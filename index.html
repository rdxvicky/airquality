<html lang="en"><head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MTech Project Report - Air Quality Prediction</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .section-title {
            color: #0d6efd;
            margin-top: 20px;
            border-bottom: 2px solid #0d6efd;
            display: inline-block;
        }
        .table-custom {
            margin-top: 20px;
        }
        .chart-placeholder {
            text-align: center;
            margin: 20px 0;
            font-style: italic;
            color: #6c757d;
        }
        footer {
            background-color: #f8f9fa;
            padding: 15px;
            text-align: center;
            margin-top: 30px;
        }
    </style>
</head>

<body>
    <div class="container">
        <header class="text-center mt-5">
            <h1>Deep Learning Approaches for Air Quality Prediction</h1>
            <h2 class="text-muted">A Comparative Study of LSTM and GRU Models</h2>
            <h5>Indian Institute of Technology Jodhpur</h5>
            <h5>School of Artificial Intelligence
                and Data Science</h5>
        </header>

        <section class="mt-5">
            <h3 class="text-center">MTech Project Report</h3>
            <p class="text-center">
                <strong>Semester I - 2023-24</strong><br>
                <strong>Submitted By:</strong>  Brijesh Kumar Karna (<strong>G24AIT025</strong>), Raj Kumar (<strong>G24AIT022</strong>), Shaktijit Rautaray (<strong>G24AIT053</strong>)<br>
                <strong>Supervised By:</strong> Dr. Asif Ekbal, Professor
            </p>
            <p class="text-center"><strong>Date:</strong> November 25, 2024</p>
        </section>

        <section>
            <h4 class="section-title">Source Code</h4>
            <p>The complete implementation is available at:</p>
            <ul>
                <li><a href="https://colab.research.google.com/drive/1S1mCfK4V71BN6FjN8RjY0urLefZ1Thvp?usp=sharing" target="_blank">Google Colab Notebook</a></li>
                <li><a href="https://gist.github.com/rdxvicky/33c7c49b48f43876e77079ceef8105b8" target="_blank">Python Implementation on GitHub</a></li>
            </ul>
        </section>

        <section>
            <h4 class="section-title">Abstract</h4>
            <p>
                This report presents a comparative analysis of Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) neural networks for air quality prediction using the UCI Air Quality dataset. Results indicate that the GRU model outperforms LSTM in accuracy and computational efficiency.
            </p>
        </section>

        <section>
            <h4 class="section-title">1. Introduction</h4>
            <p>
                Air quality prediction is crucial for environmental monitoring and public health. This study implements and compares two deep learning architectures - LSTM and GRU - for predicting CO concentration levels.
            </p>
            <ul>
                <li>Implement LSTM and GRU models for air quality prediction</li>
                <li>Compare performance metrics</li>
                <li>Analyze hyperparameter impact</li>
                <li>Evaluate computational efficiency</li>
            </ul>
        </section>

        <section>
            <h4 class="section-title">2. Methodology</h4>
            <h5>2.1 Dataset</h5>
            <p>
                Source: UCI Air Quality Dataset<br>
                Features: 12 input parameters<br>
                Target: CO concentration<br>
                Pre-processing: Removal of missing values, normalization
            </p>
            <h5>2.2 Model Architectures</h5>
            <p>
                Both models have 3 stacked layers, 64 hidden units, a dropout rate of 0.2, and a sequence length of 24 time steps.
            </p>
        </section>

        <section>
            <h4 class="section-title">3. Implementation Details</h4>
            <ul>
                <li>Data Preprocessing: Removed 8,530 rows with missing values, applied MinMaxScaler</li>
                <li>Final Dataset Shape: (827, 12)</li>
                <li>Learning Rate: 0.001, Batch Size: 32, Epochs: 100</li>
                <li>Optimization: Adam, Loss Function: Mean Squared Error</li>
            </ul>
        </section>

        <section>
            <h4 class="section-title">4. Results and Analysis</h4>
            <h5>4.1 Performance Metrics</h5>
            <table class="table table-bordered table-custom">
                <thead class="table-primary">
                    <tr>
                        <th>Metric</th>
                        <th>LSTM</th>
                        <th>GRU</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>MSE</td>
                        <td>0.6035</td>
                        <td>0.4701</td>
                    </tr>
                    <tr>
                        <td>RMSE</td>
                        <td>0.7769</td>
                        <td>0.6857</td>
                    </tr>
                    <tr>
                        <td>Training Time (seconds)</td>
                        <td>7.84</td>
                        <td>6.44</td>
                    </tr>
                    <tr>
                        <td>Final Training Loss</td>
                        <td>0.004714</td>
                        <td>0.005192</td>
                    </tr>
                </tbody>
            </table>
            <h5>4.2 Training Characteristics</h5>
            <table class="table table-striped table-custom">
                <thead>
                    <tr>
                        <th>Parameter</th>
                        <th>Value</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Input Dimension</td>
                        <td>12</td>
                    </tr>
                    <tr>
                        <td>Hidden Dimension</td>
                        <td>64</td>
                    </tr>
                    <tr>
                        <td>Dropout Rate</td>
                        <td>0.2</td>
                    </tr>
                </tbody>
            </table>
            <h5>4.3 Visualization and Analysis</h5>
            <div class="chart-wrapper" style="
    display: flex;
">
                <div class="chart-placeholder" style="
    display: flex;
    flex-direction: column;
    justify-content: center;
">
                    <img src="/Users/vicky/Desktop/video-rec-api-v2/trainningvaldation.png" style="max-width: 100%;height: auto;">
                     <span>Loss Over Epochs Plot Here</span>
                </div>
                <div class="chart-placeholder" style="display: flex;
                flex-direction: column;
                justify-content: center;">
                    <img src="/Users/vicky/Desktop/video-rec-api-v2/predictionactual.png" style="max-width: 100%; height: auto;">
                    <span>Predicted vs. Actual Values Plot Here</span>
                </div>
            </div>
        </section>

        <section>
            <h4 class="section-title">5. Conclusion</h4>
            <p>
                The GRU model demonstrated superior performance with a 22% reduction in MSE and faster training time. Future work will focus on experimenting with larger hidden dimensions and hybrid architectures.
            </p>
        </section>

        <footer>
            <p>Â© 2024 IIT Jodhpur, School Of AI & Data Science</p>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>



</body></html>
