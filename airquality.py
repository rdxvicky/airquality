# -*- coding: utf-8 -*-
"""airquality.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S1mCfK4V71BN6FjN8RjY0urLefZ1Thvp
"""

pip install ucimlrepo

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import time
from ucimlrepo import fetch_ucirepo
from datetime import datetime

# Set random seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)

def load_and_preprocess_data():
    """
    Load and preprocess the air quality dataset.
    Implements requirements from section 2 of the guidelines.
    """
    print("Starting data preprocessing...")
    start_time = time.time()

    # Fetch dataset
    air_quality = fetch_ucirepo(id=360)

    # Get features and targets
    X = air_quality.data.features
    y = air_quality.data.targets

    # Combine features and target
    df = pd.concat([X, y], axis=1)

    # Record initial size
    initial_size = len(df)

    # Remove missing values (marked as -200)
    df = df.replace(-200, np.nan)
    df = df.dropna()

    # Print information about removed rows
    final_size = len(df)
    print(f"Removed {initial_size - final_size} rows with missing values")

    # Parse Date and Time columns to create unified timestamp
    df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
    df = df.drop(['Date', 'Time'], axis=1)
    df = df.set_index('Timestamp')

    # Select target pollutant (CO)
    target_col = 'CO(GT)'
    features = df.columns.drop(['CO(GT)'])

    # Create separate scalers for features and target
    feature_scaler = MinMaxScaler()
    target_scaler = MinMaxScaler()

    # Scale features and target separately
    X_scaled = pd.DataFrame(
        feature_scaler.fit_transform(df[features]),
        columns=features,
        index=df.index
    )
    y_scaled = pd.DataFrame(
        target_scaler.fit_transform(df[[target_col]]),
        columns=[target_col],
        index=df.index
    )

    print(f"Data preprocessing completed in {time.time() - start_time:.2f} seconds")
    print(f"Final dataset shape: {X_scaled.shape}")

    return X_scaled, y_scaled, feature_scaler, target_scaler, features, target_col

class TimeSeriesDataset(Dataset):
    """Custom Dataset for loading time series data"""
    def __init__(self, X, y, sequence_length=24):
        self.X = torch.FloatTensor(X.values)
        self.y = torch.FloatTensor(y.values)
        self.sequence_length = sequence_length

    def __len__(self):
        return len(self.X) - self.sequence_length

    def __getitem__(self, idx):
        return (self.X[idx:idx+self.sequence_length],
                self.y[idx+self.sequence_length])

class BaseModel(nn.Module):
    """Base class for both LSTM and GRU models"""
    def predict(self, X):
        """Method for making predictions on new input sequences"""
        self.eval()
        with torch.no_grad():
            return self.forward(X)

class LSTMModel(BaseModel):
    """LSTM model for time series prediction"""
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(LSTMModel, self).__init__()

        # Store parameters
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim
        self.output_dim = output_dim
        self.dropout_prob = dropout_prob

        # Define LSTM layer
        self.lstm = nn.LSTM(
            input_dim, hidden_dim, layer_dim,
            batch_first=True, dropout=dropout_prob
        )

        # Define output layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        """Forward pass through LSTM layers and output prediction"""
        device = x.device
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()
        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()

        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        out = self.fc(out[:, -1, :])
        return out

class GRUModel(BaseModel):
    """GRU model for time series prediction"""
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(GRUModel, self).__init__()

        # Store parameters
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim
        self.output_dim = output_dim
        self.dropout_prob = dropout_prob

        # Define GRU layer
        self.gru = nn.GRU(
            input_dim, hidden_dim, layer_dim,
            batch_first=True, dropout=dropout_prob
        )

        # Define output layer
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        """Forward pass through GRU layers and output prediction"""
        device = x.device
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()
        out, _ = self.gru(x, h0.detach())
        out = self.fc(out[:, -1, :])
        return out

class ModelTrainer:
    """Class to handle model training and evaluation"""
    def __init__(self, model, criterion, optimizer, device):
        self.model = model.to(device)
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.train_losses = []
        self.val_losses = []
        self.training_time = 0

    def train_epoch(self, train_loader):
        """Train for one epoch"""
        self.model.train()
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch = X_batch.to(self.device)
            y_batch = y_batch.to(self.device)

            self.optimizer.zero_grad()
            y_pred = self.model(X_batch)
            loss = self.criterion(y_pred, y_batch)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()
        return total_loss / len(train_loader)

    def validate(self, val_loader):
        """Validate the model"""
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)
                y_pred = self.model(X_batch)
                loss = self.criterion(y_pred, y_batch)
                total_loss += loss.item()
        return total_loss / len(val_loader)

    def train(self, train_loader, val_loader, n_epochs):
        """Train the model"""
        print(f"\nTraining {self.model.__class__.__name__}...")
        start_time = time.time()

        for epoch in range(n_epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)

            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)

            if epoch % 10 == 0:
                print(f'Epoch {epoch}: train loss = {train_loss:.4f}, val loss = {val_loss:.4f}')

        self.training_time = time.time() - start_time
        print(f"Training completed in {self.training_time:.2f} seconds")

        # Save the model
        model_path = f'{self.model.__class__.__name__}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pth'
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
        }, model_path)
        print(f"Model saved to {model_path}")

    def evaluate(self, test_loader, scaler):
        """Evaluate the model"""
        self.model.eval()
        predictions = []
        actuals = []

        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)
                y_pred = self.model(X_batch)

                predictions.extend(y_pred.cpu().numpy())
                actuals.extend(y_batch.cpu().numpy())

        # Convert to numpy arrays and reshape
        predictions = np.array(predictions).reshape(-1, 1)
        actuals = np.array(actuals).reshape(-1, 1)

        # Inverse transform predictions and actuals
        predictions = scaler.inverse_transform(predictions)
        actuals = scaler.inverse_transform(actuals)

        # Calculate metrics
        mse = mean_squared_error(actuals, predictions)
        rmse = np.sqrt(mse)

        return {
            'mse': mse,
            'rmse': rmse,
            'predictions': predictions,
            'actuals': actuals
        }

def visualize_results(lstm_trainer, gru_trainer, lstm_metrics, gru_metrics):
    """Create visualization plots"""
    plt.figure(figsize=(20, 10))

    # Plot 1: Training and Validation Losses
    plt.subplot(2, 2, 1)
    plt.plot(lstm_trainer.train_losses, label='LSTM Train')
    plt.plot(lstm_trainer.val_losses, label='LSTM Validation')
    plt.plot(gru_trainer.train_losses, label='GRU Train')
    plt.plot(gru_trainer.val_losses, label='GRU Validation')
    plt.title('Training and Validation Losses')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # Plot 2: Predictions vs Actuals
    plt.subplot(2, 2, 2)
    plt.plot(lstm_metrics['actuals'][:100], label='Actual Values')
    plt.plot(lstm_metrics['predictions'][:100], label='LSTM Predictions')
    plt.plot(gru_metrics['predictions'][:100], label='GRU Predictions')
    plt.title('Predictions vs Actual Values (First 100 samples)')
    plt.xlabel('Time Step')
    plt.ylabel('CO Concentration')
    plt.legend()

    # Plot 3: LSTM Prediction Error
    plt.subplot(2, 2, 3)
    lstm_error = lstm_metrics['predictions'] - lstm_metrics['actuals']
    plt.hist(lstm_error, bins=50)
    plt.title('LSTM Prediction Error Distribution')
    plt.xlabel('Prediction Error')
    plt.ylabel('Frequency')

    # Plot 4: GRU Prediction Error
    plt.subplot(2, 2, 4)
    gru_error = gru_metrics['predictions'] - gru_metrics['actuals']
    plt.hist(gru_error, bins=50)
    plt.title('GRU Prediction Error Distribution')
    plt.xlabel('Prediction Error')
    plt.ylabel('Frequency')

    plt.tight_layout()
    plt.savefig('model_analysis.png')
    plt.show()

def main():
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Load and preprocess data
    X_scaled, y_scaled, feature_scaler, target_scaler, features, target_col = load_and_preprocess_data()

    # Model hyperparameters
    params = {
        'sequence_length': 24,
        'batch_size': 32,
        'input_dim': len(features),
        'hidden_dim': 64,
        'layer_dim': 3,
        'output_dim': 1,
        'dropout_prob': 0.2,
        'learning_rate': 0.001,
        'n_epochs': 100
    }

    # Split data (80% train, 20% test)
    train_size = int(0.8 * len(X_scaled))
    X_train = X_scaled[:train_size]
    X_test = X_scaled[train_size:]
    y_train = y_scaled[:train_size]
    y_test = y_scaled[train_size:]

    # Create datasets
    train_dataset = TimeSeriesDataset(X_train, y_train, params['sequence_length'])
    test_dataset = TimeSeriesDataset(X_test, y_test, params['sequence_length'])

    # Create dataloaders
    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=params['batch_size'], shuffle=False)

    # Initialize models
    lstm_model = LSTMModel(
        params['input_dim'], params['hidden_dim'], params['layer_dim'],
        params['output_dim'], params['dropout_prob']
    )
    gru_model = GRUModel(
        params['input_dim'], params['hidden_dim'], params['layer_dim'],
        params['output_dim'], params['dropout_prob']
    )

    # Initialize trainers
    criterion = nn.MSELoss()
    lstm_optimizer = torch.optim.Adam(lstm_model.parameters(), lr=params['learning_rate'])
    gru_optimizer = torch.optim.Adam(gru_model.parameters(), lr=params['learning_rate'])

    lstm_trainer = ModelTrainer(lstm_model, criterion, lstm_optimizer, device)
    gru_trainer = ModelTrainer(gru_model, criterion, gru_optimizer, device)

    # Train models
    lstm_trainer.train(train_loader, test_loader, params['n_epochs'])
    gru_trainer.train(train_loader, test_loader, params['n_epochs'])

    # Evaluate models
    print("\nEvaluating Models...")
    lstm_metrics = lstm_trainer.evaluate(test_loader, target_scaler)
    gru_metrics = gru_trainer.evaluate(test_loader, target_scaler)

    # Print results
    print("\nModel Performance Metrics:")
    print(f"LSTM - MSE: {lstm_metrics['mse']:.4f}, RMSE: {lstm_metrics['rmse']:.4f}")
    print(f"GRU  - MSE: {gru_metrics['mse']:.4f}, RMSE: {gru_metrics['rmse']:.4f}")

    # Visualize results
    visualize_results(lstm_trainer, gru_trainer, lstm_metrics, gru_metrics)

    # Generate analysis report
    generate_analysis_report(params, lstm_trainer, gru_trainer, lstm_metrics, gru_metrics)

def generate_analysis_report(params, lstm_trainer, gru_trainer, lstm_metrics, gru_metrics):
    """Generate a detailed analysis report"""
    report = f"""
Air Quality Time Series Analysis Report
=====================================
Generated on: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

1. Model Implementation
----------------------
LSTM Model:
- Architecture: {lstm_trainer.model.layer_dim} layers
- Input dimension: {lstm_trainer.model.input_dim}
- Hidden dimension: {lstm_trainer.model.hidden_dim}
- Output dimension: {lstm_trainer.model.output_dim}
- Dropout probability: {lstm_trainer.model.dropout_prob}

GRU Model:
- Architecture: {gru_trainer.model.layer_dim} layers
- Input dimension: {gru_trainer.model.input_dim}
- Hidden dimension: {gru_trainer.model.hidden_dim}
- Output dimension: {gru_trainer.model.output_dim}
- Dropout probability: {gru_trainer.model.dropout_prob}

2. Training Parameters
---------------------
- Sequence length: {params['sequence_length']}
- Batch size: {params['batch_size']}
- Learning rate: {params['learning_rate']}
- Number of epochs: {params['n_epochs']}

3. Model Performance
-------------------
LSTM Performance:
- Mean Squared Error (MSE): {lstm_metrics['mse']:.6f}
- Root Mean Squared Error (RMSE): {lstm_metrics['rmse']:.6f}
- Training time: {lstm_trainer.training_time:.2f} seconds
- Final training loss: {lstm_trainer.train_losses[-1]:.6f}
- Final validation loss: {lstm_trainer.val_losses[-1]:.6f}

GRU Performance:
- Mean Squared Error (MSE): {gru_metrics['mse']:.6f}
- Root Mean Squared Error (RMSE): {gru_metrics['rmse']:.6f}
- Training time: {gru_trainer.training_time:.2f} seconds
- Final training loss: {gru_trainer.train_losses[-1]:.6f}
- Final validation loss: {gru_trainer.val_losses[-1]:.6f}

4. Comparative Analysis
----------------------
Performance Comparison:
- {'LSTM' if lstm_metrics['mse'] < gru_metrics['mse'] else 'GRU'} achieved better MSE
- Time efficiency: {'LSTM' if lstm_trainer.training_time < gru_trainer.training_time else 'GRU'} trained faster
- {'LSTM' if lstm_trainer.val_losses[-1] < gru_trainer.val_losses[-1] else 'GRU'} showed better validation loss

5. Hyperparameter Impact
-----------------------
The current hyperparameter configuration resulted in:
- Learning rate ({params['learning_rate']}): {'Effective' if min(lstm_trainer.train_losses) < lstm_trainer.train_losses[0] else 'May need adjustment'}
- Hidden layer size ({params['hidden_dim']}): {'Sufficient' if lstm_metrics['mse'] < 1.0 else 'May need increasing'}
- Number of layers ({params['layer_dim']}): {'Adequate' if lstm_metrics['mse'] < 1.0 else 'May need adjustment'}

6. Recommendations
-----------------
Based on the analysis:
1. {'Consider increasing hidden dimension' if lstm_metrics['mse'] > 0.5 else 'Hidden dimension is adequate'}
2. {'Learning rate could be decreased' if any(l > 10*lstm_trainer.train_losses[-1] for l in lstm_trainer.train_losses) else 'Learning rate is appropriate'}
3. {'More training epochs might help' if lstm_trainer.train_losses[-1] > lstm_trainer.train_losses[-2] else 'Training epochs are sufficient'}

7. Visualization
---------------
Plots have been saved as 'model_analysis.png' showing:
- Training and validation losses over epochs
- Predictions vs actual values
- Error distribution for both models

Note: This analysis is based on the current dataset and might vary with different data or random initializations.
"""

    # Save report to file
    with open('analysis_report.txt', 'w') as f:
        f.write(report)

    print("\nAnalysis report generated and saved to 'analysis_report.txt'")

if __name__ == "__main__":
    main()

"""**Bonus Challenge:**


"""

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, r2_score
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import time
from ucimlrepo import fetch_ucirepo
from datetime import datetime
import json
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

@dataclass
class ModelConfig:
    """Configuration for model architecture and training"""
    sequence_length: int
    batch_size: int
    input_dim: int
    hidden_dim: int
    layer_dim: int
    output_dim: int
    dropout_prob: float
    learning_rate: float
    n_epochs: int
    target_pollutant: str

    @classmethod
    def from_dict(cls, config_dict: Dict) -> 'ModelConfig':
        return cls(**config_dict)

    def to_dict(self) -> Dict:
        return {
            'sequence_length': self.sequence_length,
            'batch_size': self.batch_size,
            'input_dim': self.input_dim,
            'hidden_dim': self.hidden_dim,
            'layer_dim': self.layer_dim,
            'output_dim': self.output_dim,
            'dropout_prob': self.dropout_prob,
            'learning_rate': self.learning_rate,
            'n_epochs': self.n_epochs,
            'target_pollutant': self.target_pollutant
        }

class ModelTrainer:
    """Class to handle model training and evaluation"""
    def __init__(self, model, criterion, optimizer, device):
        self.model = model.to(device)
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.train_losses = []
        self.val_losses = []
        self.training_time = 0

    def train_epoch(self, train_loader):
        """Train for one epoch"""
        self.model.train()
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch = X_batch.to(self.device)
            y_batch = y_batch.to(self.device)

            self.optimizer.zero_grad()
            y_pred = self.model(X_batch)
            loss = self.criterion(y_pred, y_batch)
            loss.backward()
            self.optimizer.step()
            total_loss += loss.item()
        return total_loss / len(train_loader)

    def validate(self, val_loader):
        """Validate the model"""
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)
                y_pred = self.model(X_batch)
                loss = self.criterion(y_pred, y_batch)
                total_loss += loss.item()
        return total_loss / len(val_loader)

    def train(self, train_loader, val_loader, n_epochs):
        """Train the model"""
        logging.info(f"\nTraining {self.model.__class__.__name__}...")
        start_time = time.time()

        for epoch in range(n_epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)

            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)

            if epoch % 10 == 0:
                logging.info(f'Epoch {epoch}: train loss = {train_loss:.4f}, val loss = {val_loss:.4f}')

        self.training_time = time.time() - start_time
        logging.info(f"Training completed in {self.training_time:.2f} seconds")

    def evaluate(self, test_loader, scaler):
        """Evaluate the model"""
        self.model.eval()
        predictions = []
        actuals = []

        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                X_batch = X_batch.to(self.device)
                y_batch = y_batch.to(self.device)
                y_pred = self.model(X_batch)

                predictions.extend(y_pred.cpu().numpy())
                actuals.extend(y_batch.cpu().numpy())

        # Convert to numpy arrays and reshape
        predictions = np.array(predictions).reshape(-1, 1)
        actuals = np.array(actuals).reshape(-1, 1)

        # Inverse transform predictions and actuals
        predictions = scaler.inverse_transform(predictions)
        actuals = scaler.inverse_transform(actuals)

        # Calculate metrics
        mse = mean_squared_error(actuals, predictions)
        rmse = np.sqrt(mse)
        r2 = r2_score(actuals, predictions)

        return {
            'mse': mse,
            'rmse': rmse,
            'r2': r2,
            'predictions': predictions,
            'actuals': actuals
        }

class TimeSeriesDataset(Dataset):
    """Custom Dataset for loading time series data"""
    def __init__(self, X, y, sequence_length=24):
        self.X = torch.FloatTensor(X.values)
        self.y = torch.FloatTensor(y.values)
        self.sequence_length = sequence_length

    def __len__(self):
        return len(self.X) - self.sequence_length

    def __getitem__(self, idx):
        return (self.X[idx:idx+self.sequence_length],
                self.y[idx+self.sequence_length])

class BaseModel(nn.Module):
    """Base class for both LSTM and GRU models"""
    def predict(self, X):
        """Method for making predictions on new input sequences"""
        self.eval()
        with torch.no_grad():
            return self.forward(X)

class LSTMModel(BaseModel):
    """LSTM model for time series prediction"""
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(LSTMModel, self).__init__()

        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim
        self.output_dim = output_dim
        self.dropout_prob = dropout_prob

        self.lstm = nn.LSTM(
            input_dim, hidden_dim, layer_dim,
            batch_first=True, dropout=dropout_prob
        )

        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        device = x.device
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()
        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()

        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))
        out = self.fc(out[:, -1, :])
        return out

class GRUModel(BaseModel):
    """GRU model for time series prediction"""
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):
        super(GRUModel, self).__init__()

        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.layer_dim = layer_dim
        self.output_dim = output_dim
        self.dropout_prob = dropout_prob

        self.gru = nn.GRU(
            input_dim, hidden_dim, layer_dim,
            batch_first=True, dropout=dropout_prob
        )

        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        device = x.device
        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device).requires_grad_()
        out, _ = self.gru(x, h0.detach())
        out = self.fc(out[:, -1, :])
        return out

class DataProcessor:
    """Handles data loading, preprocessing, and splitting"""
    def __init__(self, target_pollutant: str):
        self.target_pollutant = target_pollutant
        self.feature_scaler = MinMaxScaler()
        self.target_scaler = MinMaxScaler()

    def load_data(self) -> pd.DataFrame:
        """Load the air quality dataset"""
        air_quality = fetch_ucirepo(id=360)
        X = air_quality.data.features
        y = air_quality.data.targets
        return pd.concat([X, y], axis=1)

    def preprocess_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Preprocess the data"""
        logging.info("Starting data preprocessing...")
        initial_size = len(df)

        # Clean data
        df = df.replace(-200, np.nan)
        df = df.dropna()
        final_size = len(df)
        logging.info(f"Removed {initial_size - final_size} rows with missing values")

        # Process timestamp
        df['Timestamp'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
        df = df.drop(['Date', 'Time'], axis=1)
        df = df.set_index('Timestamp')

        # Split features and target
        features = df.columns.drop([self.target_pollutant])

        # Scale data
        X_scaled = pd.DataFrame(
            self.feature_scaler.fit_transform(df[features]),
            columns=features,
            index=df.index
        )
        y_scaled = pd.DataFrame(
            self.target_scaler.fit_transform(df[[self.target_pollutant]]),
            columns=[self.target_pollutant],
            index=df.index
        )

        return X_scaled, y_scaled

    def split_data(self, X: pd.DataFrame, y: pd.DataFrame,
                   train_ratio: float = 0.8) -> Tuple[TimeSeriesDataset, TimeSeriesDataset]:
        """Split data into train and test sets"""
        train_size = int(train_ratio * len(X))

        X_train = X[:train_size]
        X_test = X[train_size:]
        y_train = y[:train_size]
        y_test = y[train_size:]

        return (X_train, y_train), (X_test, y_test)

class ExperimentTracker:
    """Tracks and saves experiment results"""
    def __init__(self, base_dir: str = 'experiments'):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        self.experiment_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_dir = self.base_dir / self.experiment_id
        self.experiment_dir.mkdir()

    def save_config(self, config: ModelConfig):
        """Save experiment configuration"""
        with open(self.experiment_dir / 'config.json', 'w') as f:
            json.dump(config.to_dict(), f, indent=4)

    def save_metrics(self, metrics: Dict):
        """Save experiment metrics"""
        with open(self.experiment_dir / 'metrics.json', 'w') as f:
            json.dump(metrics, f, indent=4)

    def save_model(self, model: nn.Module, optimizer: torch.optim.Optimizer,
                  model_name: str):
        """Save model checkpoint"""
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
        }, self.experiment_dir / f'{model_name}.pth')

    def save_plots(self, fig: plt.Figure, name: str):
        """Save visualization plots"""
        fig.savefig(self.experiment_dir / f'{name}.png')

class ExperimentRunner:
    """Manages experiment execution"""
    def __init__(self, config: ModelConfig, device: torch.device):
        self.config = config
        self.device = device
        self.tracker = ExperimentTracker()
        self.tracker.save_config(config)

    def run_experiment(self):
        """Execute the experiment"""
        # Initialize data processor
        data_processor = DataProcessor(self.config.target_pollutant)

        # Load and preprocess data
        df = data_processor.load_data()
        X_scaled, y_scaled = data_processor.preprocess_data(df)

        # Update input dimension based on actual features
        self.config.input_dim = X_scaled.shape[1]

        # Split data
        (X_train, y_train), (X_test, y_test) = data_processor.split_data(X_scaled, y_scaled)

        # Create datasets
        train_dataset = TimeSeriesDataset(X_train, y_train, self.config.sequence_length)
        test_dataset = TimeSeriesDataset(X_test, y_test, self.config.sequence_length)

        # Create dataloaders
        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size, shuffle=False)

        # Train and evaluate models
        models = {
            'LSTM': self._train_model(LSTMModel, train_loader, test_loader),
            'GRU': self._train_model(GRUModel, train_loader, test_loader)
        }

        # Evaluate and compare models
        self._evaluate_models(models, test_loader, data_processor.target_scaler)

    def _train_model(self, model_class, train_loader, test_loader):
        """Train a single model"""
        model = model_class(
            self.config.input_dim, self.config.hidden_dim,
            self.config.layer_dim, self.config.output_dim,
            self.config.dropout_prob
        ).to(self.device)

        optimizer = torch.optim.Adam(model.parameters(), lr=self.config.learning_rate)
        criterion = nn.MSELoss()

        trainer = ModelTrainer(model, criterion, optimizer, self.device)
        trainer.train(train_loader, test_loader, self.config.n_epochs)

        return trainer

    def _evaluate_models(self, models, test_loader, target_scaler):
        """Evaluate and compare models"""
        results = {}
        for name, trainer in models.items():
            metrics = trainer.evaluate(test_loader, target_scaler)
            results[name] = {
                'mse': float(metrics['mse']),
                'rmse': float(metrics['rmse']),
                'r2': float(metrics['r2']),
                'training_time': trainer.training_time
            }

            self.tracker.save_model(trainer.model, trainer.optimizer, name)

        self.tracker.save_metrics(results)
        self._create_comparison_plots(models, results)

    def _create_comparison_plots(self, models, results):
        """Create and save comparison plots"""
        fig = plt.figure(figsize=(20, 15))

        # Plot training losses
        plt.subplot(2, 2, 1)
        for name, trainer in models.items():
            plt.plot(trainer.train_losses, label=f'{name} Train')
            plt.plot(trainer.val_losses, label=f'{name} Validation')
        plt.title('Training and Validation Losses')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()

        # Plot metrics comparison
        plt.subplot(2, 2, 2)
        metrics = ['mse', 'rmse', 'r2']
        x = np.arange(len(metrics))
        width = 0.35

        for i, (name, metrics_dict) in enumerate(results.items()):
            values = [metrics_dict[metric] for metric in metrics]
            plt.bar(x + i*width, values, width, label=name)

        plt.xlabel('Metrics')
        plt.ylabel('Value')
        plt.title('Model Comparison')
        plt.xticks(x + width/2, metrics)
        plt.legend()

        plt.tight_layout()
        self.tracker.save_plots(fig, 'model_comparison')

def main():
    # Set device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    logging.info(f"Using device: {device}")

    # Define comprehensive set of configurations to experiment with
    configurations = [
        # Original configurations
        {
            'sequence_length': 24,
            'batch_size': 32,
            'input_dim': 0,  # Will be set based on data
            'hidden_dim': 64,
            'layer_dim': 3,
            'output_dim': 1,
            'dropout_prob': 0.2,
            'learning_rate': 0.001,
            'n_epochs': 100,
            'target_pollutant': 'CO(GT)'
        },
        {
            'sequence_length': 24,
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 128,
            'layer_dim': 4,
            'output_dim': 1,
            'dropout_prob': 0.3,
            'learning_rate': 0.0005,
            'n_epochs': 100,
            'target_pollutant': 'NO2(GT)'
        },
        # Configuration for longer sequence length
        {
            'sequence_length': 48,  # Increased sequence length for longer-term patterns
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 128,
            'layer_dim': 3,
            'output_dim': 1,
            'dropout_prob': 0.2,
            'learning_rate': 0.001,
            'n_epochs': 150,  # Increased epochs for longer sequences
            'target_pollutant': 'CO(GT)'
        },
        # Configuration for deeper network
        {
            'sequence_length': 24,
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 256,  # Larger hidden dimension
            'layer_dim': 5,     # More layers
            'output_dim': 1,
            'dropout_prob': 0.4, # Higher dropout for deeper network
            'learning_rate': 0.0003,
            'n_epochs': 120,
            'target_pollutant': 'NO2(GT)'
        },
        # Configuration for smaller batch size and higher learning rate
        {
    'sequence_length': 24,
    'batch_size': 16,
    'input_dim': 0,
    'hidden_dim': 128,
    'layer_dim': 3,
    'output_dim': 1,
    'dropout_prob': 0.2,
    'learning_rate': 0.002,
    'n_epochs': 100,
    'target_pollutant': 'PT08.S5(O3)'  # Updated target pollutant
},

        # Configuration for very deep network with regularization
        {
            'sequence_length': 24,
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 512,  # Much larger hidden dimension
            'layer_dim': 6,     # Many layers
            'output_dim': 1,
            'dropout_prob': 0.5, # Strong dropout
            'learning_rate': 0.0002,
            'n_epochs': 150,
            'target_pollutant': 'NO2(GT)'
        },
        # Configuration for very long sequences
        {
            'sequence_length': 72,  # 3 days of hourly data
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 256,
            'layer_dim': 4,
            'output_dim': 1,
            'dropout_prob': 0.3,
            'learning_rate': 0.0005,
            'n_epochs': 200,    # More epochs for longer sequences
            'target_pollutant': 'CO(GT)'
        },
        # Configuration for multi-pollutant prediction (if supported)
        {
            'sequence_length': 24,
            'batch_size': 32,
            'input_dim': 0,
            'hidden_dim': 256,
            'layer_dim': 4,
            'output_dim': 1,    # Could be modified for multi-output
            'dropout_prob': 0.3,
            'learning_rate': 0.0008,
            'n_epochs': 120,
            'target_pollutant': 'NMHC(GT)'  # Different target pollutant
        }
    ]

    # Run experiments with different configurations
    for config_dict in configurations:
        config = ModelConfig.from_dict(config_dict)
        logging.info(f"\nStarting experiment with target pollutant: {config.target_pollutant}")
        logging.info(f"Configuration: {config}")

        runner = ExperimentRunner(config, device)
        runner.run_experiment()

if __name__ == "__main__":
    main()